{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convert the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "514266it [24:55, 343.91it/s]\n"
     ]
    }
   ],
   "source": [
    "local_path = './models/gpt4all-lora-quantized-ggml.bin'\n",
    "Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "url = 'https://the-eye.eu/public/AI/models/nomic-ai/gpt4all/gpt4all-lora-quantized-ggml.bin'\n",
    "\n",
    "# send a GET request to the URL to download the file.\n",
    "response = requests.get(url, stream=True)\n",
    "\n",
    "# open the file in binary mode and write the contents of the response\n",
    "# to it in chunks.\n",
    "with open(local_path, 'wb') as f:\n",
    "    for chunk in tqdm(response.iter_content(chunk_size=8192)):\n",
    "        if chunk:\n",
    "            f.write(chunk)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the Model and Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GPT4All\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.callbacks.base import BaseCallbackManager\n",
    "# from langchain.callbacks.manager import AsyncCallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /home/quan/anaconda3/envs/langchain/lib/python3.9/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllmodel.so)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m callback_manager \u001b[39m=\u001b[39m BaseCallbackManager([StreamingStdOutCallbackHandler()])\n\u001b[0;32m----> 2\u001b[0m llm \u001b[39m=\u001b[39m GPT4All(model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./models/ggml-model-q4_0.bin\u001b[39;49m\u001b[39m\"\u001b[39;49m, callback_manager\u001b[39m=\u001b[39;49mcallback_manager, verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      3\u001b[0m llm_chain \u001b[39m=\u001b[39m LLMChain(prompt\u001b[39m=\u001b[39mprompt, llm\u001b[39m=\u001b[39mllm)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/langchain_core/load/serializable.py:107\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    108\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lc_kwargs \u001b[39m=\u001b[39m kwargs\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/pydantic/v1/main.py:339\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mCreate a new model by parsing and validating input data from keyword arguments.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39mRaises ValidationError if the input data cannot be parsed to form a valid model.\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m values, fields_set, validation_error \u001b[39m=\u001b[39m validate_model(__pydantic_self__\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m, data)\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m validation_error:\n\u001b[1;32m    341\u001b[0m     \u001b[39mraise\u001b[39;00m validation_error\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/pydantic/v1/main.py:1100\u001b[0m, in \u001b[0;36mvalidate_model\u001b[0;34m(model, input_data, cls)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1100\u001b[0m     values \u001b[39m=\u001b[39m validator(cls_, values)\n\u001b[1;32m   1101\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m, \u001b[39mAssertionError\u001b[39;00m) \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m   1102\u001b[0m     errors\u001b[39m.\u001b[39mappend(ErrorWrapper(exc, loc\u001b[39m=\u001b[39mROOT_KEY))\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/langchain_community/llms/gpt4all.py:134\u001b[0m, in \u001b[0;36mGPT4All.validate_environment\u001b[0;34m(cls, values)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Validate that the python package exists in the environment.\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgpt4all\u001b[39;00m \u001b[39mimport\u001b[39;00m GPT4All \u001b[39mas\u001b[39;00m GPT4AllModel\n\u001b[1;32m    135\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m    137\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCould not import gpt4all python package. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease install it with `pip install gpt4all`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/gpt4all/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgpt4all\u001b[39;00m \u001b[39mimport\u001b[39;00m Embed4All \u001b[39mas\u001b[39;00m Embed4All, GPT4All \u001b[39mas\u001b[39;00m GPT4All\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/gpt4all/gpt4all.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39murllib3\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m IncompleteRead, ProtocolError\n\u001b[0;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _pyllmodel\n\u001b[1;32m     20\u001b[0m \u001b[39m# TODO: move to config\u001b[39;00m\n\u001b[1;32m     21\u001b[0m DEFAULT_MODEL_DIRECTORY \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(Path\u001b[39m.\u001b[39mhome()), \u001b[39m\"\u001b[39m\u001b[39m.cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgpt4all\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/gpt4all/_pyllmodel.py:38\u001b[0m\n\u001b[1;32m     33\u001b[0m         lib \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mCDLL(\u001b[39mstr\u001b[39m(MODEL_LIB_PATH \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mllmodel.dll\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\n\u001b[0;32m---> 38\u001b[0m llmodel \u001b[39m=\u001b[39m load_llmodel_library()\n\u001b[1;32m     41\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mLLModelPromptContext\u001b[39;00m(ctypes\u001b[39m.\u001b[39mStructure):\n\u001b[1;32m     42\u001b[0m     _fields_ \u001b[39m=\u001b[39m [\n\u001b[1;32m     43\u001b[0m         (\u001b[39m\"\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m\"\u001b[39m, ctypes\u001b[39m.\u001b[39mPOINTER(ctypes\u001b[39m.\u001b[39mc_float)),\n\u001b[1;32m     44\u001b[0m         (\u001b[39m\"\u001b[39m\u001b[39mlogits_size\u001b[39m\u001b[39m\"\u001b[39m, ctypes\u001b[39m.\u001b[39mc_size_t),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m         (\u001b[39m\"\u001b[39m\u001b[39mcontext_erase\u001b[39m\u001b[39m\"\u001b[39m, ctypes\u001b[39m.\u001b[39mc_float),\n\u001b[1;32m     57\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/gpt4all/_pyllmodel.py:28\u001b[0m, in \u001b[0;36mload_llmodel_library\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m ext \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mDarwin\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mdylib\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLinux\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mso\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mWindows\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mdll\u001b[39m\u001b[39m\"\u001b[39m}[platform\u001b[39m.\u001b[39msystem()]\n\u001b[1;32m     26\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[39m# Linux, Windows, MinGW\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     lib \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39;49mCDLL(\u001b[39mstr\u001b[39;49m(MODEL_LIB_PATH \u001b[39m/\u001b[39;49m \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlibllmodel.\u001b[39;49m\u001b[39m{\u001b[39;49;00mext\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     29\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m ext \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdll\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/ctypes/__init__.py:382\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_FuncPtr \u001b[39m=\u001b[39m _FuncPtr\n\u001b[1;32m    381\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, mode)\n\u001b[1;32m    383\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /home/quan/anaconda3/envs/langchain/lib/python3.9/site-packages/gpt4all/llmodel_DO_NOT_MODIFY/build/libllmodel.so)"
     ]
    }
   ],
   "source": [
    "callback_manager = BaseCallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = GPT4All(model=\"./models/ggml-model-q4_0.bin\", callback_manager=callback_manager, verbose=True)\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
