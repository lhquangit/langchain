{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Output Parsers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. PydanticOutputParser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Generate output in a JSON format\n",
    "\n",
    "- Treat parser's output as a list -> be possible to index through the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator, field_validator\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(discriminator=\"list of substitue words based on context\")\n",
    "\n",
    "    # Throw error in case of receiving a numbered-list from API\n",
    "    @field_validator('words')\n",
    "    def not_start_with_number(cls, field):\n",
    "        for item in field:\n",
    "            if item[0].isnumeric():\n",
    "                raise ValueError(\"The word can not start with numbers!\")\n",
    "        return field\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Offer a list of suggestions to substitue the specified target_word based the presented context.\n",
    "{format_instructions}\n",
    "target_word={target_word}\n",
    "context={context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"target_word\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "model_input = prompt.format_prompt(\n",
    "\t\t\ttarget_word=\"behaviour\",\n",
    "\t\t\tcontext=\"The behaviour of the students in the classroom was disruptive and made it difficult for the teacher to conduct the lesson.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quan/anaconda3/envs/langchain/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n",
      "/home/quan/anaconda3/envs/langchain/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Suggestions(words=['conduct', 'manage', 'handle', 'oversee', 'facilitate'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "model = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0.0)\n",
    "\n",
    "output = model(model_input.to_string())\n",
    "\n",
    "parser.parse(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple Outputs Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Offer a list of suggestions to substitute the specified target_word based on the presented context and the reasoning for each word.\n",
    "{format_instructions}\n",
    "target_word={target_word}\n",
    "context={context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
    "    reasons: List[str] = Field(description=\"the reasoning of why this word fits the context\")\n",
    "    \n",
    "    @field_validator('words')\n",
    "    def not_start_with_number(cls, field):\n",
    "      for item in field:\n",
    "        if item[0].isnumeric():\n",
    "          raise ValueError(\"The word can not start with numbers!\")\n",
    "      return field\n",
    "    \n",
    "    @field_validator('reasons')\n",
    "    def end_with_dot(cls, field):\n",
    "      for idx, item in enumerate( field ):\n",
    "        if item[-1] != \".\":\n",
    "          field[idx] += \".\"\n",
    "      return field\n",
    "parser = PydanticOutputParser(pydantic_object=Suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"target_word\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "model_input = prompt.format_prompt(\n",
    "\t\t\ttarget_word=\"behaviour\",\n",
    "\t\t\tcontext=\"The behaviour of the students in the classroom was disruptive and made it difficult for the teacher to conduct the lesson.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suggestions(words=['conduct', 'manage', 'handle', 'oversee'], reasons=[\"These words all imply a sense of control and authority, which is lacking in the original context. They also suggest a more active role in guiding the students' actions.\"])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0.0)\n",
    "\n",
    "output = model(model_input.to_string())\n",
    "\n",
    "parser.parse(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. CommaSeparatedOutputParser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  It manages comma-separated outputs\n",
    "\n",
    "-  It handles one specific case: anytime you want to receive a list of outputs from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Conduct\\n2. Manner\\n3. Demeanor\\n4. Conducting\\n5. Attitude\\n6. Conductance\\n7. Deportment\\n8. Etiquette\\n9. Performance\\n10. Actions']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Prepare the Prompt\n",
    "template = \"\"\"\n",
    "Offer a list of suggestions to substitute the word '{target_word}' based the presented the following text: {context}.\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"target_word\", \"context\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "model_input = prompt.format(\n",
    "  target_word=\"behaviour\",\n",
    "  context=\"The behaviour of the students in the classroom was disruptive and made it difficult for the teacher to conduct the lesson.\"\n",
    ")\n",
    "\n",
    "# Loading OpenAI API\n",
    "model = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0.0)\n",
    "\n",
    "# Send the Request\n",
    "output = model(model_input)\n",
    "parser.parse(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3. StructuredOutputParser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first output parser implemented by the LangChain team. While it can process multiple outputs, it only supports texts and does not provide options for other data types, such as lists or integers. It can be used when you want to receive one response from the model. For example, only one substitute word in the thesaurus application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"words\", description=\"A substitue word based on context\"),\n",
    "    ResponseSchema(name=\"reasons\", description=\"the reasoning of why this word fits the context.\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fixing Errors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. OutputFixingParser"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method tries to fix the parsing error by looking at the model’s response and the previous parser. It uses a Large Language Model (LLM) to solve the issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Suggestions\nreasons\n  Field required [type=missing, input_value={'words': ['conduct', 'ma...particular situation.']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 14\u001b[0m\n\u001b[1;32m     10\u001b[0m parser \u001b[39m=\u001b[39m PydanticOutputParser(pydantic_object\u001b[39m=\u001b[39mSuggestions)\n\u001b[1;32m     12\u001b[0m missformatted_output \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwords\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconduct\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmanner\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m], \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreasoning\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrefers to the way someone acts in a particular situation.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrefers to the way someone behaves in a particular situation.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]}\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 14\u001b[0m parser\u001b[39m.\u001b[39;49mparse(missformatted_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/langchain/output_parsers/pydantic.py:34\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     32\u001b[0m         json_str \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mgroup()\n\u001b[1;32m     33\u001b[0m     json_object \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(json_str, strict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 34\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpydantic_object\u001b[39m.\u001b[39;49mparse_obj(json_object)\n\u001b[1;32m     36\u001b[0m \u001b[39mexcept\u001b[39;00m (json\u001b[39m.\u001b[39mJSONDecodeError, ValidationError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     37\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpydantic_object\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/pydantic/main.py:1072\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1067\u001b[0m \u001b[39m@typing_extensions\u001b[39m\u001b[39m.\u001b[39mdeprecated(\u001b[39m'\u001b[39m\u001b[39mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[39m'\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1068\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_obj\u001b[39m(\u001b[39mcls\u001b[39m: \u001b[39mtype\u001b[39m[Model], obj: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Model:  \u001b[39m# noqa: D102\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1070\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[39m'\u001b[39m, category\u001b[39m=\u001b[39mPydanticDeprecatedSince20\n\u001b[1;32m   1071\u001b[0m     )\n\u001b[0;32m-> 1072\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_validate(obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/pydantic/main.py:509\u001b[0m, in \u001b[0;36mBaseModel.model_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    508\u001b[0m __tracebackhide__ \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__pydantic_validator__\u001b[39m.\u001b[39;49mvalidate_python(\n\u001b[1;32m    510\u001b[0m     obj, strict\u001b[39m=\u001b[39;49mstrict, from_attributes\u001b[39m=\u001b[39;49mfrom_attributes, context\u001b[39m=\u001b[39;49mcontext\n\u001b[1;32m    511\u001b[0m )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Suggestions\nreasons\n  Field required [type=missing, input_value={'words': ['conduct', 'ma...particular situation.']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
    "    reasons: List[str] = Field(description=\"the reasoning of why this word fits the context\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Suggestions)\n",
    "\n",
    "missformatted_output = '{\"words\": [\"conduct\", \"manner\"], \"reasoning\": [\"refers to the way someone acts in a particular situation.\", \"refers to the way someone behaves in a particular situation.\"]}'\n",
    "\n",
    "parser.parse(missformatted_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the error message, the parser correctly identified an error in our sample response (missformatted_output) since we used the word **reasoning** instead of the expected **reasons** key.\n",
    "\n",
    "The OutputFixingParser class could easily fix this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for Suggestions\nreasons\n  Field required [type=missing, input_value={'words': ['conduct', 'ma...particular situation.']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m model \u001b[39m=\u001b[39m OpenAI(model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgpt-3.5-turbo-instruct\u001b[39m\u001b[39m'\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m)\n\u001b[1;32m     16\u001b[0m outputfixing_parser \u001b[39m=\u001b[39m OutputFixingParser\u001b[39m.\u001b[39mfrom_llm(parser\u001b[39m=\u001b[39mparser, llm\u001b[39m=\u001b[39mmodel)\n\u001b[0;32m---> 17\u001b[0m outputfixing_parser\u001b[39m.\u001b[39;49mparse(missformatted_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/langchain/output_parsers/fix.py:59\u001b[0m, in \u001b[0;36mOutputFixingParser.parse\u001b[0;34m(self, completion)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mwhile\u001b[39;00m retries \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_retries:\n\u001b[1;32m     58\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparser\u001b[39m.\u001b[39;49mparse(completion)\n\u001b[1;32m     60\u001b[0m     \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     61\u001b[0m         \u001b[39mif\u001b[39;00m retries \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_retries:\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/langchain/output_parsers/pydantic.py:34\u001b[0m, in \u001b[0;36mPydanticOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     32\u001b[0m         json_str \u001b[39m=\u001b[39m match\u001b[39m.\u001b[39mgroup()\n\u001b[1;32m     33\u001b[0m     json_object \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(json_str, strict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 34\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpydantic_object\u001b[39m.\u001b[39;49mparse_obj(json_object)\n\u001b[1;32m     36\u001b[0m \u001b[39mexcept\u001b[39;00m (json\u001b[39m.\u001b[39mJSONDecodeError, ValidationError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     37\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpydantic_object\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/pydantic/main.py:1072\u001b[0m, in \u001b[0;36mBaseModel.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m   1067\u001b[0m \u001b[39m@typing_extensions\u001b[39m\u001b[39m.\u001b[39mdeprecated(\u001b[39m'\u001b[39m\u001b[39mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[39m'\u001b[39m, category\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1068\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_obj\u001b[39m(\u001b[39mcls\u001b[39m: \u001b[39mtype\u001b[39m[Model], obj: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Model:  \u001b[39m# noqa: D102\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1070\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mThe `parse_obj` method is deprecated; use `model_validate` instead.\u001b[39m\u001b[39m'\u001b[39m, category\u001b[39m=\u001b[39mPydanticDeprecatedSince20\n\u001b[1;32m   1071\u001b[0m     )\n\u001b[0;32m-> 1072\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_validate(obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.9/site-packages/pydantic/main.py:509\u001b[0m, in \u001b[0;36mBaseModel.model_validate\u001b[0;34m(cls, obj, strict, from_attributes, context)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[39m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    508\u001b[0m __tracebackhide__ \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m__pydantic_validator__\u001b[39m.\u001b[39;49mvalidate_python(\n\u001b[1;32m    510\u001b[0m     obj, strict\u001b[39m=\u001b[39;49mstrict, from_attributes\u001b[39m=\u001b[39;49mfrom_attributes, context\u001b[39m=\u001b[39;49mcontext\n\u001b[1;32m    511\u001b[0m )\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for Suggestions\nreasons\n  Field required [type=missing, input_value={'words': ['conduct', 'ma...particular situation.']}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Suggestions(BaseModel):\n",
    "    words: List[str] = Field(description=\"list of substitue words based on context\")\n",
    "    reasons: List[str] = Field(description=\"the reasoning of why this word fits the context\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Suggestions)\n",
    "\n",
    "missformatted_output = '{\"words\": [\"conduct\", \"manner\"], \"reasoning\": [\"refers to the way someone acts in a particular situation.\", \"refers to the way someone behaves in a particular situation.\"]}'\n",
    "\n",
    "\n",
    "model = OpenAI(model_name='gpt-3.5-turbo-instruct', temperature=0.0)\n",
    "\n",
    "outputfixing_parser = OutputFixingParser.from_llm(parser=parser, llm=model)\n",
    "outputfixing_parser.parse(missformatted_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
